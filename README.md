# ğŸ“Š Retail Analytics Chat

An AI-powered retail analytics system that lets users query transaction data through a conversational chat interface. Built with **React**, **Flask**, **PostgreSQL**, and **OpenAI GPT-4o-mini**.

## Local Setup & Run

```bash
# 1. Clone the repository
git clone https://github.com/YOUR_USERNAME/retail-analytics-chat.git
cd retail-analytics-chat

# 2. Add your OpenAI API key
echo "OPENAI_API_KEY=sk-your-key-here" > backend/.env

# 3. Start all services
docker compose up

# 4. Seed the database (first run only â€” run in a separate terminal)
docker compose exec backend python seed.py
```

Once running, open:
- **Chat UI:** [http://localhost:3000](http://localhost:3000)
- **Backend API:** [http://localhost:5000](http://localhost:5000)
- **pgAdmin (optional):** [http://localhost:5050](http://localhost:5050) â€” login: `admin@admin.com` / `admin`


## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React UI   â”‚â”€â”€â”€â”€â–¶â”‚  Flask Backend                    â”‚â”€â”€â”€â”€â–¶â”‚ PostgreSQL â”‚
â”‚  (Vite)     â”‚â—€â”€â”€â”€â”€â”‚  /api/chat    â†’ LLM + Data Layer â”‚â—€â”€â”€â”€â”€â”‚            â”‚
â”‚  Port 3000  â”‚     â”‚  /api/customers/:id               â”‚     â”‚  Port 5432 â”‚
â”‚             â”‚     â”‚  /api/products/:id                â”‚     â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ OpenAI API   â”‚
                      â”‚ GPT-4o-mini  â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Query flow:**
1. User sends a natural language question via the chat UI
2. Backend sends the question to GPT-4o-mini for **intent classification** (customer, product, business metric, comparison, or off-topic)
3. Backend extracts entity IDs and queries PostgreSQL accordingly
4. Retrieved data is sent back to GPT-4o-mini to generate a **natural language response**
5. Response + optional charts are returned to the frontend

## Tech Stack

| Layer     | Technology                          |
|-----------|-------------------------------------|
| Frontend  | React 19, Vite, Recharts            |
| Backend   | Python, Flask, SQLAlchemy           |
| Database  | PostgreSQL 16                       |
| LLM       | OpenAI GPT-4o-mini                  |
| Infra     | Docker Compose                      |

## Prerequisites

- Docker Desktop
- OpenAI API key

## Dataset Setup

The project uses the [Kaggle Retail Transaction Dataset](https://www.kaggle.com/datasets/fahadrehman07/retail-transaction-dataset/data).

The CSV file is already included at `backend/data/Retail_Transaction_Dataset.csv`. If you need to re-download it, place it in `backend/data/`

## Environment Variables

Create a `backend/.env` file with your OpenAI API key:

```env
OPENAI_API_KEY=sk-your-key-here
```

## Example Queries

### Customer Queries
- `What has customer 109318 purchased?`
- `How much has customer 993229 spent in total?`
- `Show me the purchase history for customer 109318`

### Product Queries
- `What's the average discount for product A?`
- `Which stores sell product B?`
- `Tell me about product D`

### Business Metrics
- `What is the total revenue by category?`
- `How many unique customers are there?`
- `What are the most popular payment methods?`

### Comparison Queries (Bonus)
- `Compare product A vs product B`
- `Compare customer 109318 vs customer 993229`

### Edge Case Handling
- `Tell me a joke` â†’ Politely rejected as off-topic
- Empty message â†’ Prompted to enter a question
- Non-existent ID â†’ Clear "no data found" message

## REST API Endpoints

| Method | Endpoint               | Description                            |
|--------|------------------------|----------------------------------------|
| POST   | `/api/chat`            | Send a natural language query           |
| GET    | `/api/customers/<id>`  | Get transactions for a customer         |
| GET    | `/api/products/<id>`   | Get aggregated stats for a product      |
| GET    | `/health`              | Health check                            |

## Project Structure

```
retail-analytics-chat/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ seed.py                      # Database seeder
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ Retail_Transaction_Dataset.csv
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py              # Flask app factory
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ models.py                # SQLAlchemy Transaction model
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py              # Chat endpoint (orchestrator)
â”‚   â”‚   â”‚   â”œâ”€â”€ customers.py         # Customer REST API
â”‚   â”‚   â”‚   â”œâ”€â”€ products.py          # Product REST API
â”‚   â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ llm_service.py       # OpenAI integration
â”‚   â”‚       â”œâ”€â”€ prompts.py           # System & classification prompts
â”‚   â”‚       â”œâ”€â”€ data_service.py      # Data access & formatting
â”‚   â”‚       â””â”€â”€ chart_service.py     # Chart data generation
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ index.css
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageBubble.jsx
â”‚   â”‚   â”‚   â””â”€â”€ ChartPanel.jsx
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.js
```

## Key Technical Decisions

- **Intent classification via LLM** â€” GPT-4o-mini classifies each query into one of: `customer_query`, `product_query`, `business_metric`, `comparison`, `off_topic`, or `general`. This avoids brittle regex-based routing.
- **Two-pass LLM approach** â€” First call classifies intent and extracts IDs; second call generates the natural language response from retrieved data. This keeps each prompt focused and reliable.
- **PostgreSQL over SQLite** â€” Chosen for indexed queries on `customer_id` and `product_id` columns, better concurrency, and production readiness.
- **Structured chart data** â€” Backend returns chart-ready JSON; frontend renders it with Recharts. No image generation needed.
- **Edge case handling** â€” Off-topic detection, input length cap (500 chars), case-insensitive ID matching, and graceful error responses.